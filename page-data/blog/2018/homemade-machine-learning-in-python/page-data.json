{"componentChunkName":"component---src-templates-post-tsx-content-file-path-src-posts-2018-homemade-machine-learning-in-python-index-md","path":"/blog/2018/homemade-machine-learning-in-python/","result":{"data":{"mdx":{"id":"7dfe1292-a3e6-5db9-a991-e20c1c59c831","body":"\r\n![Homemade Machine Learning in Python](assets/01-cover.png)\r\n\r\n<center><i>\r\nThe source of the following machine learning topics map is <a href=\"https://vas3k.ru/blog/machine_learning/\">this wonderful blog post</a>.\r\n</i></center>\r\n\r\nI’ve recently launched [Homemade Machine Learning](https://github.com/trekhleb/homemade-machine-learning) repository that contains examples of popular machine learning algorithms and approaches (like _linear/logistic regressions, K-Means clustering, neural networks_) implemented in **Python** with mathematics behind them being explained. Each algorithm has interactive **Jupyter Notebook** demo that allows you to play with training data, algorithms configurations and immediately see the results, charts and predictions **right in your browser**. In most cases the explanations are based on [this great machine learning course](https://www.coursera.org/learn/machine-learning) by [Andrew Ng](https://medium.com/@andrewng).\r\n\r\nThe purpose of the repository was _not_ to implement machine learning algorithms by using 3rd party library “one-liners” _but_ rather to practice implementing these algorithms from scratch and get better understanding of the mathematics behind each algorithm. That’s why all algorithms implementations are called “homemade”.\r\n\r\nThe main Python libraries that are used there are [NumPy](http://www.numpy.org/) and [Pandas](https://pandas.pydata.org/). These two are used for efficient matrix operations and for loading/parsing CSV datasets. When it comes to [Jupyter Notebook](http://jupyter.org/) demos then such libraries as [Matplotlib](https://matplotlib.org/) and [Plotly](https://plot.ly/) are being used for data visualizations.\r\n\r\nCurrently, the following topics have been covered:\r\n\r\n## Regression: Linear Regression\r\n\r\nIn regression problems we do real value predictions. Basically we try to draw a line/plane/n-dimensional plane along the training examples.\r\n\r\n_Usage examples: stock price forecast, sales analysis, dependency of any number, etc._\r\n\r\n*   📗 [Linear Regression Math](https://github.com/trekhleb/homemade-machine-learning/blob/master/homemade/linear_regression)  —  theory and links for further readings\r\n*   ⚙️ [Linear Regression Implementation Example](https://github.com/trekhleb/homemade-machine-learning/blob/master/homemade/linear_regression/linear_regression.py)\r\n*   ▶️ [Demo | Univariate Linear Regression](https://nbviewer.jupyter.org/github/trekhleb/homemade-machine-learning/blob/master/notebooks/linear_regression/univariate_linear_regression_demo.ipynb)  —  predict `country happiness` score by `economy GDP`\r\n*   ▶️ [Demo | Multivariate Linear Regression](https://nbviewer.jupyter.org/github/trekhleb/homemade-machine-learning/blob/master/notebooks/linear_regression/multivariate_linear_regression_demo.ipynb)  —  predict `country happiness` score by `economy GDP` and `freedom index`\r\n*   ▶️ [Demo | Non-linear Regression](https://nbviewer.jupyter.org/github/trekhleb/homemade-machine-learning/blob/master/notebooks/linear_regression/non_linear_regression_demo.ipynb)  —  use linear regression with _polynomial_ and _sinusoid_ features to predict non-linear dependencies.\r\n\r\n## Classification: Logistic Regression\r\n\r\nIn classification problems we split input examples by certain characteristic.\r\n\r\n_Usage examples: spam-filters, language detection, finding similar documents, handwritten letters recognition, etc._\r\n\r\n*   📗 [Logistic Regression Math](https://github.com/trekhleb/homemade-machine-learning/blob/master/homemade/logistic_regression)  —  theory and links for further readings\r\n*   ⚙️ [Logistic Regression Implementation Example](https://github.com/trekhleb/homemade-machine-learning/blob/master/homemade/logistic_regression/logistic_regression.py)\r\n*   ▶️ [Demo | Logistic Regression (Linear Boundary)](https://nbviewer.jupyter.org/github/trekhleb/homemade-machine-learning/blob/master/notebooks/logistic_regression/logistic_regression_with_linear_boundary_demo.ipynb)  —  predict Iris flower `class` based on `petal_length` and `petal_width`\r\n*   ▶️ [Demo | Logistic Regression (Non-Linear Boundary)](https://nbviewer.jupyter.org/github/trekhleb/homemade-machine-learning/blob/master/notebooks/logistic_regression/logistic_regression_with_non_linear_boundary_demo.ipynb)  —  predict microchip `validity` based on `param_1` and `param_2`\r\n*   ▶️ [Demo | Multivariate Logistic Regression](https://nbviewer.jupyter.org/github/trekhleb/homemade-machine-learning/blob/master/notebooks/logistic_regression/multivariate_logistic_regression_demo.ipynb)  —  recognize handwritten digits from `28x28` pixel images.\r\n\r\n## Clustering: K-means Algorithm\r\n\r\nIn clustering problems we split the training examples by unknown characteristics. The algorithm itself decides what characteristic to use for splitting.\r\n\r\n_Usage examples: market segmentation, social networks analysis, organize computing clusters, astronomical data analysis, image compression, etc._\r\n\r\n*   📗 [K-means Algorithm Math](https://github.com/trekhleb/homemade-machine-learning/blob/master/homemade/k_means)  —  theory and links for further readings\r\n*   ⚙️ [K-means Algorithm Implementation Example](https://github.com/trekhleb/homemade-machine-learning/blob/master/homemade/k_means/k_means.py)\r\n*   ▶️ [Demo | K-means Algorithm](https://nbviewer.jupyter.org/github/trekhleb/homemade-machine-learning/blob/master/notebooks/k_means/k_means_demo.ipynb)  —  split Iris flowers into clusters based on `petal_length` and `petal_width`\r\n\r\n## Neural Networks: Multilayer Perceptron (MLP)\r\n\r\nThe neural network itself isn’t an algorithm, but rather a framework for many different machine learning algorithms to work together and process complex data inputs.\r\n\r\n_Usage examples: as a substitute of all other algorithms in general, image recognition, voice recognition, image processing (applying specific style), language translation, etc._\r\n\r\n*   📗 [Multilayer Perceptron Math](https://github.com/trekhleb/homemade-machine-learning/blob/master/homemade/neural_network)  —  theory and links for further readings\r\n*   ⚙️ [Multilayer Perceptron Implementation Example](https://github.com/trekhleb/homemade-machine-learning/blob/master/homemade/neural_network/multilayer_perceptron.py)\r\n*   ▶️ [Demo | Multilayer Perceptron](https://nbviewer.jupyter.org/github/trekhleb/homemade-machine-learning/blob/master/notebooks/neural_network/multilayer_perceptron_demo.ipynb)  —  recognize handwritten digits from `28x28` pixel images.\r\n\r\n## Anomaly Detection: Gaussian Distribution\r\n\r\nAnomaly detection (also outlier detection) is the identification of rare items, events or observations which raise suspicions by differing significantly from the majority of the data.\r\n\r\n_Usage examples: intrusion detection, fraud detection, system health monitoring, removing anomalous data from the dataset etc._\r\n\r\n*   📗 [The Math Behind Anomaly Detection using Gaussian Distribution](https://github.com/trekhleb/homemade-machine-learning/blob/master/homemade/anomaly_detection)\r\n\r\n> I hope you’ll find [the repository](https://github.com/trekhleb/homemade-machine-learning) useful. Either by playing with demos or by reading the math sections or by simply exploring the source code. Happy coding!\r\n","fields":{"slug":"/blog/2018/homemade-machine-learning-in-python/"},"internal":{"contentFilePath":"C:/prj/quangphucphung.github.io/src/posts/2018/homemade-machine-learning-in-python/index.md"},"frontmatter":{"title":"Homemade Machine Learning in Python","summary":"MatLab/Octave examples of popular machine learning algorithms with code examples and mathematics being explained","date":"21 December, 2018","cover":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","backgroundColor":"#f8f8f8","images":{"fallback":{"src":"/static/6a4daeb4f4a615338ca192f7993816ae/04028/01-cover.png","srcSet":"/static/6a4daeb4f4a615338ca192f7993816ae/aa366/01-cover.png 750w,\n/static/6a4daeb4f4a615338ca192f7993816ae/b0379/01-cover.png 1080w,\n/static/6a4daeb4f4a615338ca192f7993816ae/04028/01-cover.png 1207w","sizes":"100vw"},"sources":[{"srcSet":"/static/6a4daeb4f4a615338ca192f7993816ae/8e1db/01-cover.webp 750w,\n/static/6a4daeb4f4a615338ca192f7993816ae/54c44/01-cover.webp 1080w,\n/static/6a4daeb4f4a615338ca192f7993816ae/01d89/01-cover.webp 1207w","type":"image/webp","sizes":"100vw"}]},"width":1,"height":0.6975973487986744}}}}}},"pageContext":{"slug":"/blog/2018/homemade-machine-learning-in-python/","frontmatter":{"title":"Homemade Machine Learning in Python","summary":"MatLab/Octave examples of popular machine learning algorithms with code examples and mathematics being explained","cover":"assets/01-cover.png","date":"2018-12-21T00:00:00.000Z"}}},"staticQueryHashes":["3196427994"],"slicesMap":{}}