{"componentChunkName":"component---src-templates-post-tsx-content-file-path-src-posts-2018-homemade-machine-learning-in-python-index-md","path":"/blog/2018/homemade-machine-learning-in-python/","result":{"data":{"mdx":{"id":"7dfe1292-a3e6-5db9-a991-e20c1c59c831","body":"\r\n![Homemade Machine Learning in Python](assets/01-cover.png)\r\n\r\n<center><i>\r\nThe source of the following machine learning topics map is <a href=\"https://vas3k.ru/blog/machine_learning/\">this wonderful blog post</a>.\r\n</i></center>\r\n\r\nIâ€™ve recently launched [Homemade Machine Learning](https://github.com/trekhleb/homemade-machine-learning) repository that contains examples of popular machine learning algorithms and approaches (like _linear/logistic regressions, K-Means clustering, neural networks_) implemented in **Python** with mathematics behind them being explained. Each algorithm has interactive **Jupyter Notebook** demo that allows you to play with training data, algorithms configurations and immediately see the results, charts and predictions **right in your browser**. In most cases the explanations are based on [this great machine learning course](https://www.coursera.org/learn/machine-learning) by [Andrew Ng](https://medium.com/@andrewng).\r\n\r\nThe purpose of the repository was _not_ to implement machine learning algorithms by using 3rd party library â€œone-linersâ€ _but_ rather to practice implementing these algorithms from scratch and get better understanding of the mathematics behind each algorithm. Thatâ€™s why all algorithms implementations are called â€œhomemadeâ€.\r\n\r\nThe main Python libraries that are used there are [NumPy](http://www.numpy.org/) and [Pandas](https://pandas.pydata.org/). These two are used for efficient matrix operations and for loading/parsing CSV datasets. When it comes to [Jupyter Notebook](http://jupyter.org/) demos then such libraries as [Matplotlib](https://matplotlib.org/) and [Plotly](https://plot.ly/) are being used for data visualizations.\r\n\r\nCurrently, the following topics have been covered:\r\n\r\n## Regression: Linear Regression\r\n\r\nIn regression problems we do real value predictions. Basically we try to draw a line/plane/n-dimensional plane along the training examples.\r\n\r\n_Usage examples: stock price forecast, sales analysis, dependency of any number, etc._\r\n\r\n*   ðŸ“— [Linear Regression Math](https://github.com/trekhleb/homemade-machine-learning/blob/master/homemade/linear_regression)  â€”  theory and links for further readings\r\n*   âš™ï¸ [Linear Regression Implementation Example](https://github.com/trekhleb/homemade-machine-learning/blob/master/homemade/linear_regression/linear_regression.py)\r\n*   â–¶ï¸ [Demo | Univariate Linear Regression](https://nbviewer.jupyter.org/github/trekhleb/homemade-machine-learning/blob/master/notebooks/linear_regression/univariate_linear_regression_demo.ipynb)  â€”  predict `country happiness` score by `economy GDP`\r\n*   â–¶ï¸ [Demo | Multivariate Linear Regression](https://nbviewer.jupyter.org/github/trekhleb/homemade-machine-learning/blob/master/notebooks/linear_regression/multivariate_linear_regression_demo.ipynb)  â€”  predict `country happiness` score by `economy GDP` and `freedom index`\r\n*   â–¶ï¸ [Demo | Non-linear Regression](https://nbviewer.jupyter.org/github/trekhleb/homemade-machine-learning/blob/master/notebooks/linear_regression/non_linear_regression_demo.ipynb)  â€”  use linear regression with _polynomial_ and _sinusoid_ features to predict non-linear dependencies.\r\n\r\n## Classification: Logistic Regression\r\n\r\nIn classification problems we split input examples by certain characteristic.\r\n\r\n_Usage examples: spam-filters, language detection, finding similar documents, handwritten letters recognition, etc._\r\n\r\n*   ðŸ“— [Logistic Regression Math](https://github.com/trekhleb/homemade-machine-learning/blob/master/homemade/logistic_regression)  â€”  theory and links for further readings\r\n*   âš™ï¸ [Logistic Regression Implementation Example](https://github.com/trekhleb/homemade-machine-learning/blob/master/homemade/logistic_regression/logistic_regression.py)\r\n*   â–¶ï¸ [Demo | Logistic Regression (Linear Boundary)](https://nbviewer.jupyter.org/github/trekhleb/homemade-machine-learning/blob/master/notebooks/logistic_regression/logistic_regression_with_linear_boundary_demo.ipynb)  â€”  predict Iris flower `class` based on `petal_length` and `petal_width`\r\n*   â–¶ï¸ [Demo | Logistic Regression (Non-Linear Boundary)](https://nbviewer.jupyter.org/github/trekhleb/homemade-machine-learning/blob/master/notebooks/logistic_regression/logistic_regression_with_non_linear_boundary_demo.ipynb)  â€”  predict microchip `validity` based on `param_1` and `param_2`\r\n*   â–¶ï¸ [Demo | Multivariate Logistic Regression](https://nbviewer.jupyter.org/github/trekhleb/homemade-machine-learning/blob/master/notebooks/logistic_regression/multivariate_logistic_regression_demo.ipynb)  â€”  recognize handwritten digits from `28x28` pixel images.\r\n\r\n## Clustering: K-means Algorithm\r\n\r\nIn clustering problems we split the training examples by unknown characteristics. The algorithm itself decides what characteristic to use for splitting.\r\n\r\n_Usage examples: market segmentation, social networks analysis, organize computing clusters, astronomical data analysis, image compression, etc._\r\n\r\n*   ðŸ“— [K-means Algorithm Math](https://github.com/trekhleb/homemade-machine-learning/blob/master/homemade/k_means)  â€”  theory and links for further readings\r\n*   âš™ï¸ [K-means Algorithm Implementation Example](https://github.com/trekhleb/homemade-machine-learning/blob/master/homemade/k_means/k_means.py)\r\n*   â–¶ï¸ [Demo | K-means Algorithm](https://nbviewer.jupyter.org/github/trekhleb/homemade-machine-learning/blob/master/notebooks/k_means/k_means_demo.ipynb)  â€”  split Iris flowers into clusters based on `petal_length` and `petal_width`\r\n\r\n## Neural Networks: Multilayer Perceptron (MLP)\r\n\r\nThe neural network itself isnâ€™t an algorithm, but rather a framework for many different machine learning algorithms to work together and process complex data inputs.\r\n\r\n_Usage examples: as a substitute of all other algorithms in general, image recognition, voice recognition, image processing (applying specific style), language translation, etc._\r\n\r\n*   ðŸ“— [Multilayer Perceptron Math](https://github.com/trekhleb/homemade-machine-learning/blob/master/homemade/neural_network)  â€”  theory and links for further readings\r\n*   âš™ï¸ [Multilayer Perceptron Implementation Example](https://github.com/trekhleb/homemade-machine-learning/blob/master/homemade/neural_network/multilayer_perceptron.py)\r\n*   â–¶ï¸ [Demo | Multilayer Perceptron](https://nbviewer.jupyter.org/github/trekhleb/homemade-machine-learning/blob/master/notebooks/neural_network/multilayer_perceptron_demo.ipynb)  â€”  recognize handwritten digits from `28x28` pixel images.\r\n\r\n## Anomaly Detection: Gaussian Distribution\r\n\r\nAnomaly detection (also outlier detection) is the identification of rare items, events or observations which raise suspicions by differing significantly from the majority of the data.\r\n\r\n_Usage examples: intrusion detection, fraud detection, system health monitoring, removing anomalous data from the dataset etc._\r\n\r\n*   ðŸ“— [The Math Behind Anomaly Detection using Gaussian Distribution](https://github.com/trekhleb/homemade-machine-learning/blob/master/homemade/anomaly_detection)\r\n\r\n> I hope youâ€™ll find [the repository](https://github.com/trekhleb/homemade-machine-learning) useful. Either by playing with demos or by reading the math sections or by simply exploring the source code. Happy coding!\r\n","fields":{"slug":"/blog/2018/homemade-machine-learning-in-python/"},"internal":{"contentFilePath":"C:/prj/quangphucphung.github.io/src/posts/2018/homemade-machine-learning-in-python/index.md"},"frontmatter":{"title":"Homemade Machine Learning in Python","summary":"MatLab/Octave examples of popular machine learning algorithms with code examples and mathematics being explained","date":"21 December, 2018","cover":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","backgroundColor":"#f8f8f8","images":{"fallback":{"src":"/static/6a4daeb4f4a615338ca192f7993816ae/04028/01-cover.png","srcSet":"/static/6a4daeb4f4a615338ca192f7993816ae/aa366/01-cover.png 750w,\n/static/6a4daeb4f4a615338ca192f7993816ae/b0379/01-cover.png 1080w,\n/static/6a4daeb4f4a615338ca192f7993816ae/04028/01-cover.png 1207w","sizes":"100vw"},"sources":[{"srcSet":"/static/6a4daeb4f4a615338ca192f7993816ae/8e1db/01-cover.webp 750w,\n/static/6a4daeb4f4a615338ca192f7993816ae/54c44/01-cover.webp 1080w,\n/static/6a4daeb4f4a615338ca192f7993816ae/01d89/01-cover.webp 1207w","type":"image/webp","sizes":"100vw"}]},"width":1,"height":0.6975973487986744}}}}}},"pageContext":{"slug":"/blog/2018/homemade-machine-learning-in-python/","frontmatter":{"title":"Homemade Machine Learning in Python","summary":"MatLab/Octave examples of popular machine learning algorithms with code examples and mathematics being explained","cover":"assets/01-cover.png","date":"2018-12-21T00:00:00.000Z"}}},"staticQueryHashes":["3196427994"],"slicesMap":{}}